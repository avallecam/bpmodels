---
title: "Projecting infectious disease incidence using early outbreak data"
author: "James Azam, Sebastian Funk"
output:
  bookdown::html_vignette2:
    fig_caption: yes
    code_folding: show
pkgdown:
  as_is: true
bibliography: references.bib
link-citations: true
vignette: >
  %\VignetteIndexEntry{Projecting infectious disease incidence using early outbreak data}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE, 
                      collapse = TRUE,
                      comment = "#>"
                      )

```

## Overview

Branching processes can be used to project infectious disease trends provided 
we can characterize the distribution of times between 
successive cases (serial interval), and the distribution of secondary cases 
produced by a single individual (offspring distribution). Such simulations can 
be achieved in `bpmodels` with the `chain_sim()` function and @Pearson2020, and 
@abbott2020 illustrate its application to COVID-19. 

The purpose of this vignette is to use early data on COVID-19 in South Africa 
[@marivate2020] to illustrate how `bpmodels` can be used to forecast an 
outbreak. 


Let's load the required packages

```{r packages, include=TRUE}
library("bpmodels")
library("dplyr")
library("ggplot2")
library("lubridate")
```

## Data

Included in `bpmodels` is a cleaned time series of the first 15 days of 
the COVID-19 outbreak in South Africa. This can be loaded into 
memory as follows: 
```{r}
data('covid19_sa', package = 'bpmodels')
```

Let us examine the first 6 entries of the dataset.
```{r}
head(covid19_sa)
```

## Setting up the inputs  

### Onset times 
`chain_sim()` requires a vector of onset times, `t0`, for each 
chain/individual/simulation. 

The `covid19_sa` dataset above is aggregated, so we will have to disaggregate
it into a linelist with each row representing a case and their onset time. 

To achieve this, we will first use the date of the index case as the reference 
and find the difference between each date and the reference. 
```{r linelist_gen, message=FALSE}
days_since_index <- as.integer(covid19_sa$date - min(covid19_sa$date))
days_since_index
```

Using the times created above, we will then create the linelist
by disaggregating the time series so that each case has a 
corresponding start time.
```{r}
start_times <- unlist(mapply(
  function(x, y) rep(x, times = ifelse(y == 0, 1, y)),
  days_since_index,
  covid19_sa$cases
))

start_times
```

### Serial interval

The log-normal distribution is [commonly used in epidemiology](https://ete-online.biomedcentral.com/articles/10.1186/1742-7622-4-2) 
to characterise quantities such as the serial interval because it tends to 
have a large variance and can only be positive-valued. The log-normal 
distribution is right-skewed and assumes positive real-numbered values, hence
often models the serial interval appropriately. 

In this example, we will assume based on COVID-19 literature that the 
serial interval, S, is log-normal distributed with parameters, 
$\mu = 4.7$ and $\sigma = 2.9$ [@Pearson2020]. Note that when the distribution
is described this way, it means $\mu$ and $\sigma$ are the expected value 
and standard deviation of the natural logarithm of the serial interval. Hence, 
in order to sample the untransformed serial interval with expectation/mean, 
$E[S]$ and standard deviation, $SD [S]$, we can use the following 
parametrisation:

\begin{align}
E[S] &= \ln \left( \dfrac{\mu^2}{(\sqrt{\mu^2 + \sigma^2}} \right) \\

SD [S] &= \sqrt {\ln \left(1 + \dfrac{\sigma^2}{\mu^2} \right)}
 
\end{align}

See [Wikipedia](https://en.wikipedia.org/wiki/Log-normal_distribution) for a 
detailed explanation of this parametrisation.

The [epiparameter](https://github.com/epiverse-trace/epiparameter) R package 
provides the function `epiparameter::lnorm_meansd2musigma()` for implementing 
this parametrisation. It takes as inputs the mean, $\mu$ and standard 
deviation, $\sigma$ and returns a list with the transformed mean and 
standard deviation. Refer to `?epiparamete::lnorm_meansd2musigma` 
for more details.

Let us set up the serial interval with this information:
```{r input_prep3, message=FALSE}
mu <- 4.7
sgma <- 2.9

log_mean <- epiparameter::lnorm_meansd2musigma(mu, sgma)[[1]]  # log mean
log_sd <- epiparameter::lnorm_meansd2musigma(mu, sgma)[[2]] # log standard deviation

#' serial interval function
serial_interval <- function(sample_size) {
  si <- rlnorm(sample_size, meanlog = log_mean, sdlog = log_sd)
  return(si)
}
```

### Offspring distribution

The negative binomial distribution is commonly used in epidemiology to
account for [individual variation in transmissibility](https://www.nature.com/articles/nature04153), also known as superspreading.

For this example, we will assume that the offspring distribution is 
characterised by a negative binomial with $R = 2.5$ [@abbott2020] and 
$k = 0.58$ [@Wang2020]. In this parameterization, $R$ 
represents the $R_0$, which is defined as the average number of 
cases produced by a single individual in an entirely susceptible population. 
The parameter $k$ represents superspreading, that is, the degree of 
heterogeneity in transmission by single individuals.


### Simulation controls

`chain_sim()` also requires the end time for the simulations. For this 
example, we will simulate outbreaks that end 14 days after the last date 
of observations in `covid19_sa`.   
```{r input_prep2, message=FALSE}
#' Date to end simulation (14 day projection in this case)
projection_window <- 14 # 14 days/ 2-week ahead projection
projection_end_day <- max(days_since_index) + projection_window
projection_end_day
```

`chain_sim()` is stochastic, meaning the results are different every 
time it is run for the same set of parameters, so we will run the simulations
many times and summarise the results. 

We will, therefore, run each simulation $100$ times.
```{r}
#' Number of simulations
sim_rep <- 100
```

Lastly, `chain_sim()` requires the maximum size of each chain. 
Above this value, the simulation is cut off. If this value is 
not specified, it assumes a value of infinity. Here, we will
assume a maximum chain size of $1000$.
```{r}
#' Maximum chain size allowed
chain_threshold <- 1000
```


## Modelling assumptions

`chain_sim()` makes the following simplifying assumptions:

1. All cases are observed
1. There is no reporting delay
1. Reporting rate is constant through the course of the epidemic
1. No interventions have been implemented
1. Population is homogeneous and well-mixed

```{r simulations, message=FALSE}
set.seed(1234)
sim_chain_sizes <- lapply(
  seq_len(sim_rep),
  function(sim) {
    chain_sim(
      n = length(start_times),
      offspring = "nbinom",
      mu = 2.5,
      size = 0.58,
      stat = "size",
      infinite = chain_threshold,
      serial = serial_interval,
      t0 = start_times,
      tf = projection_end_day,
      tree = TRUE
    ) %>%
      mutate(sim = sim)
  }
)

sim_output <- bind_rows(sim_chain_sizes)

head(sim_output)
```

## Post-processing

From the simulated data, we will count the median daily cases 
(`median_daily_cases`) across all simulations and overlay that on the results 
of all the projections through time (`incidence_ts`).

```{r post_processing}
index_date <- min(covid19_sa$date)
index_date
# Daily number of cases for each simulation
incidence_ts <- sim_output %>%
  mutate(day = ceiling(time)) %>%
  group_by(sim, day) %>%
  summarise(cases = n()) %>%
  ungroup()

head(incidence_ts)

# Add dates
incidence_ts_by_date <- incidence_ts %>%
  group_by(sim) %>%
  mutate(date = index_date + days(seq(0, n() - 1))) %>%
  ungroup()

head(incidence_ts_by_date)
# Median daily number of cases aggregated across all simulations
median_daily_cases <- incidence_ts %>%
  group_by(day) %>%
  summarise(median_cases = median(cases)) %>%
  ungroup() %>%
  arrange(day)

head(median_daily_cases)

# Add dates
median_daily_cases <- median_daily_cases %>%
  mutate(date = index_date + days(seq(0, projection_end_day))) %>%
  ungroup()

head(median_daily_cases)
```


## Visualization

```{r viz, fig.cap ="COVID-19 incidence projected over a two week window. The gray lines represent individual simulations, red connected dots represent the median daily cases across all simulations, and the black triangles represent the observed data.", fig.width=4.0, fig.height=3.8}
# Visualization
ggplot(data = incidence_ts_by_date) +
  geom_line(aes(
    x = date,
    y = cases,
    group = sim
  ),
  color = "grey",
  linewidth = 1.2,
  alpha = 0.25
  ) +
  geom_point(
    data = median_daily_cases,
    aes(
      x = date,
      y = median_cases
    ),
    color = "tomato3",
    size = 0.75
  ) +
  geom_line(
    data = median_daily_cases,
    aes(
      x = date,
      y = median_cases
    ),
    color = "tomato3",
    linewidth = 0.25
  ) +
  geom_point(
    data = covid19_sa,
    aes(
      x = date,
      y = cases
    ),
    color = "black",
    size = 0.25,
    shape = 24
  ) +
  scale_x_continuous(
    breaks = seq(min(incidence_ts_by_date$date), max(incidence_ts_by_date$date), 10),
    labels = seq(min(incidence_ts_by_date$date), max(incidence_ts_by_date$date), 10)
  ) +
  scale_y_continuous(
    breaks = seq(0, max(incidence_ts_by_date$cases) + 200, 250),
    labels = seq(0, max(incidence_ts_by_date$cases) + 200, 250)
  ) +
  labs(x = "Date", y = "Daily cases (median)") +
  theme_minimal() 
```

## References
