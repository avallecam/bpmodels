---
title: "Projecting infectious disease incidence using early outbreak data"
author: "James Azam, Sebastian Funk"
output:
  bookdown::html_vignette2:
    fig_caption: yes
    code_folding: show
pkgdown:
  as_is: true
bibliography: references.bib
link-citations: true
vignette: >
  %\VignetteIndexEntry{Projecting infectious disease incidence using early outbreak data}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE, 
                      collapse = TRUE,
                      comment = "#>",
                      dpi = 300
                      )

```

## Overview

Branching processes can be used to project infectious disease trends provided 
we can characterize the distribution of times between 
successive cases (serial interval), and the distribution of secondary cases 
produced by a single individual (offspring distribution). Such simulations can 
be achieved in `bpmodels` with the `chain_sim()` function. @Pearson2020, and 
@abbott2020 illustrate its application to COVID-19. 

The purpose of this vignette is to use early data on COVID-19 in South Africa 
[@marivate2020] to illustrate how `bpmodels` can be used to forecast an 
outbreak. 


Let's load the required packages

```{r packages, include=TRUE}
library("bpmodels")
library("dplyr")
library("ggplot2")
library("lubridate")
```

## Data

We will get and clean the first $15$ days of the COVID-19 
outbreak in South Africa to seed the simulation for this example.

```{r data, message=FALSE}
data_url <- 'https://raw.githubusercontent.com/dsfsi/covid19za/master/data/covid19za_timeline_confirmed.csv' # nolint: line_length_linter. 

#Read the data in using the url
covid19_sa <- read.csv(data_url)

# Subset the first 15 days and count the number of cases per date
covid19_sa <- covid19_sa %>% 
  select(date) %>% 
  mutate(date = lubridate::dmy(date)) %>%
  filter(date <= min(date) + lubridate::days(15)) %>%   
  group_by(date) %>% 
  summarise(cases = n()) %>%   
  ungroup()
```

## Inputs  
Using the data above, we will set up a vector of start times for each case.

```{r linelist_gen, message=FALSE}
days_since_index <- as.integer(covid19_sa$date - min(covid19_sa$date))

start_times <- unlist(mapply(
  function(x, y) rep(x, times = ifelse(y == 0, 1, y)),
  days_since_index,
  covid19_sa$cases
))
                       
```


Additionally, `chain_sim()` requires the end time for the simulations and the 
maximum size of each chain. Since each result of `chain_sim()` is stochastic,
it is also best to run it many times. 

We will specify these as follows:

```{r input_prep2, message=FALSE}
#' Date to end simulation (14 day projection in this case)

projection_window <- 14 # 14 days/ 2-week ahead projection

projection_end_day <- max(days_since_index) + projection_window

#' Number of simulations
sim_rep <- 100

#' Maximum chain size allowed
chain_threshold <- 1000

```

### Serial interval

In this example, we will assume based on COVID-19 literature that the 
serial interval, $\mathcal{S}$, is log-normal distributed with parameters, 
$\mu = 4.7$ and $\sigma = 2.9$ [@Pearson2020]. The log-normal mean, 
$E[ \mathcal{S} ]$ and standard deviation $SD[ \mathcal{S} ]$ are 
characterised as:

\begin{align}
E[ \mathcal{S} ] &= \ln \left( \dfrac{\mu^2}{(\sqrt{\mu^2 + \sigma^2}} \right) \\

SD [ \mathcal{S} ] &= \sqrt {\ln \left(1 + \dfrac{\sigma^2}{\mu^2} \right)}
 
\end{align}

See [Wikipedia](https://en.wikipedia.org/wiki/Log-normal_distribution) for a 
detailed explanation of this parametrisation.

The following is how we set up the serial interval function using the
information provided above:

```{r input_prep3, message=FALSE}
mu <- 4.7

sigma <- 2.9

log_sd <- sqrt(log(1 + (sigma / mu)^2)) # log standard deviation

log_mean <- log((mu^2) / (sqrt(sigma^2 + mu^2))) # log mean

#' serial interval function
serial_interval <- function(sample_size) {
  si <- rlnorm(sample_size, meanlog = log_mean, sdlog = log_sd)
  return(si)
}
```

### Offspring distribution

We will also assume that the offspring distribution is characterised by a 
negative binomial with $\mathcal{R} = 2.5$ [@abbott2020] and 
$\mathcal{k} = 0.58$ [@Wang2020]. In this parameterization, $\mathcal{R}$ 
represents the $\mathcal{R_0}$, which is defined as the average number of 
cases produced by a single individual in an entirely susceptible population. 
The parameter $k$ represents superspreading, that is, the degree of 
heterogeneity in transmission by single individuals.

## Simulations
To summarize the simulation set up, for each of the `r sim_rep` simulations,
we want to project cases over a `r projection_window` day period since the 
last case, assuming that no chain would exceed `r chain_threshold`. 

### Model assumptions

`chain_sim()` makes the following simplifying assumptions:

1. All cases are observed
1. There is no reporting delay
1. Reporting rate is constant through the course of the epidemic
1. No interventions have been implemented
1. Population is homogeneous and well-mixed

```{r simulations, message=FALSE}
set.seed(1234)


sim_chain_sizes <- lapply(
  seq_len(sim_rep),
  function(sim) {
    chain_sim(
      n = length(start_times),
      offspring = "nbinom",
      mu = 2.5,
      size = 0.58,
      stat = "size",
      infinite = chain_threshold,
      serial = serial_interval,
      t0 = start_times,
      tf = projection_end_day,
      tree = TRUE
    ) %>%
      mutate(sim = sim)
  }
)

sim_output <- bind_rows(sim_chain_sizes)

head(sim_output)
```

## Post-processing

From the simulated data, we will count the median daily cases 
(`median_daily_cases`) across all simulations and overlay that on the results 
of all the projections through time (`incidence_ts`).

```{r post_processing}
index_date <- min(covid19_sa$date)

# Daily number of cases for each simulation
incidence_ts <- sim_output %>%
  mutate(day = ceiling(time)) %>%
  group_by(sim, day) %>%
  summarise(cases = n()) %>%
  ungroup()

# Add dates
incidence_ts <- incidence_ts %>%
  group_by(sim) %>%
  mutate(date = index_date + days(seq(0, n() - 1))) %>%
  ungroup()

## Median daily number of cases aggregated across all simulations
median_daily_cases <- incidence_ts %>%
  group_by(day) %>%
  summarise(median_cases = median(cases)) %>%
  ungroup() %>%
  arrange(day)

# Add dates
median_daily_cases <- median_daily_cases %>%
  mutate(date = index_date + days(seq(0, projection_end_day))) %>%
  ungroup()

```


## Visualization

```{r viz, fig.cap ="COVID-19 incidence projected over a two week window. The gray lines represent individual simulations, red connected dots represent the median daily cases across all simulations, and the black triangles represent the observed data.", fig.width=2.0, fig.height=1.8}
# Visualization
ggplot(data = incidence_ts) +
  geom_line(aes(
    x = date,
    y = cases,
    group = sim
  ),
  color = "grey",
  linewidth = 1.2,
  alpha = 0.25
  ) +
  geom_point(
    data = median_daily_cases,
    aes(
      x = date,
      y = median_cases
    ),
    color = "tomato3",
    size = 0.75
  ) +
  geom_line(
    data = median_daily_cases,
    aes(
      x = date,
      y = median_cases
    ),
    color = "tomato3",
    linewidth = 0.25
  ) +
  geom_point(
    data = covid19_sa,
    aes(
      x = date,
      y = cases
    ),
    color = "black",
    size = 0.25,
    shape = 24
  ) +
  scale_x_continuous(
    breaks = seq(min(incidence_ts$date), max(incidence_ts$date), 10),
    labels = seq(min(incidence_ts$date), max(incidence_ts$date), 10)
  ) +
  scale_y_continuous(
    breaks = seq(0, max(incidence_ts$cases) + 200, 250),
    labels = seq(0, max(incidence_ts$cases) + 200, 250)
  ) +
  labs(x = "Date", y = "Daily cases (median)") +
  theme_minimal() 
```

## References
